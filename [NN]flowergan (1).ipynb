{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[NN]flowergan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEKwTDNgeX4s"
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Importation of necessary modules\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "from numpy import *\n",
        "\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnctLacklff_",
        "outputId": "a273e5d8-6919-4b60-a776-264c55fec913"
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Downloading the flower dataset\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "#This allows to download the pictures from tensorflow\n",
        "#We need to know where it is downloaded so we can use them\n",
        "URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "PIL_file = tf.keras.utils.get_file(origin=URL, fname='flower_photos', untar=True)\n",
        "PIL_file = pathlib.Path(PIL_file)\n",
        "\n",
        "#Size chosen for easier convolution : 160 = 5*2^4\n",
        "height = 160\n",
        "width = 160\n",
        "\n",
        "#We are taking all the images of the dataset in one batch because we want to convert them to \n",
        "#numpy array in order to use the same code as the Cifar10 dataset \n",
        "PIL_dataset = tf.keras.preprocessing.image_dataset_from_directory(PIL_file,image_size=(height, width),batch_size=3670) \n",
        "\n",
        "\n",
        "#This will transform the Images into a numpy array that we can feed to our code as is\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1)\n",
        "dataset = PIL_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "dataset,_ = next(iter(dataset))\n",
        "dataset=dataset.numpy()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3670 files belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o2iiM0hByVR"
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Definition of general variables needed in the code\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "ldim = 50 #This is the dimension that will serve to generate the noise that the generator will use : the latent space\n",
        "epoch=100 #This is the number of times the training process will happen\n",
        "\n",
        "batch=32 #This is the number of images that we will use for one epoch\n",
        "#The discriminator will have to judge a batch coming from the dataset and a batch from the generator.\n",
        "#The generator will create two batches of images\n",
        "\n",
        "Image_size=(160,160,3) #Setting the image size of the flowers database : (dimension1, dimension2, black&white(1) or color(3))\n",
        "\n",
        "Optimizer = Adam(lr=0.0002, beta_1=0.5) #Those values are the best ones for an optimizer according to the DCGAN paper\n",
        "Loss = 'mse' #This is the mean-squared error. To compare with the binary crossentropy results we write 'binary-crossentropy' instead\n",
        "Activation = 'linear' #This is the activation function for the LSGAN. If we are using binary crossentropy we change it to 'sigmoid'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9MiZDw_B5xy"
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Definition of the discriminator model\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "discriminator = Sequential()\n",
        "discriminator.add(Conv2D(64, (5,5), strides=(2, 2), padding='same', input_shape=Image_size))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(0.4))\n",
        "\n",
        "discriminator.add(Conv2D(256, (5,5), strides=(2, 2), padding='same'))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(0.4))\n",
        "\n",
        "discriminator.add(Conv2D(256, (5,5), strides=(2, 2), padding='same'))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(0.4))\n",
        "\n",
        "discriminator.add(Conv2D(256, (5,5), strides=(2, 2), padding='same'))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(0.4))\n",
        "\n",
        "discriminator.add(Conv2D(256, (5,5), strides=(2, 2), padding='same'))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(0.4))\n",
        "\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(1, activation=Activation))\n",
        "\n",
        "discriminator.compile(loss=Loss, optimizer=Optimizer, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK4DsAjrB6p0"
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Definition of the generator model\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "generator = Sequential()\n",
        "\n",
        "generator.add(Dense(256*5*5, input_dim=ldim))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(Reshape((5, 5, 256)))\n",
        " \n",
        "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "generator.add(Conv2D(3, (3,3), activation='tanh', padding='same'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddaalA2dB8jc"
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Definition of the gan model\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "#This will be used for generator training\n",
        "#In order to train the generator, we have to put the discriminator as untrainable\n",
        "#The discriminator is already compiled so it will not change its training\n",
        "discriminator.trainable = False \n",
        "\n",
        "#The gan is simply composed of both the generator and the discriminator\n",
        "gan = Sequential()\n",
        "gan.add(generator)\n",
        "gan.add(discriminator)\n",
        "gan.compile(loss=Loss, optimizer=Optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdrFY3hDCCyW",
        "outputId": "12192200-681f-49eb-822d-50af7e6bbf5e"
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Training of the models\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "#We are making a loop to train the model for as many epoch as stated\n",
        "for i in range(epoch):\n",
        "\n",
        "\n",
        "#In this GAN, the discriminator and the generator are trained at the same pace \n",
        "#which is not necessarily the case for all GANs (example the WGAN)\n",
        "\n",
        "\n",
        "#####Discriminator training#####\n",
        "\n",
        "\t#Choosing real images randomly from the database\n",
        "\timage_index = randint(0, dataset.shape[0], batch)\n",
        "\treal_images = dataset[image_index] #These are the real images\n",
        "\treal_label = ones((batch, 1)) #1 is the label for real images\n",
        "\n",
        "\t#Generating a random noise as input of the generator in order to generate different images\n",
        "\tnoise = randn(ldim * batch)\n",
        "\tnoise = noise.reshape(batch, ldim)\n",
        "\tfake_images = generator.predict(noise) #This is the fake images\n",
        "\tfake_label = zeros((batch, 1)) #0 is the label for fake images\n",
        "\n",
        "\t#Stacking the real and fake images together for training of the discriminator\n",
        "\t#This function creates 1 array from 2 arrays\n",
        "\timages = vstack((real_images, fake_images))\n",
        "\tlabels = vstack((real_label, fake_label))\n",
        " \n",
        "  #The train_on_batch() function runs a gradient update on this batch of data\n",
        "  #The discriminator gets images as input data and has to guess the labels correctly\n",
        "  #This function returns the training loss\n",
        "\tdiscriminator_loss, _ = discriminator.train_on_batch(images, labels)\n",
        "\n",
        "\n",
        "#####Generator training#####\n",
        "\n",
        "\t#Noise generation as input of the generator training\n",
        "\tnoise = randn(ldim * batch * 2)\n",
        "\tnoise = noise.reshape(batch*2, ldim)\n",
        "\t#The generated images should aim to be recognized as real by the discriminator, which will be untrainable during the next step\n",
        "\treal_labelg = ones((batch*2, 1))\n",
        " \n",
        " #We have the noise as input data and the generator will have to create an image that will be classified as real\n",
        "\tgenerator_loss = gan.train_on_batch(noise, real_labelg)\n",
        " \n",
        " #The information of the losses of the discriminator and generator is crucial because it gives us information on the training process\n",
        " #If the values are too high or equal to 0, something went wrong and the training should be restarted\n",
        "\tprint('%d, d=%.3f, g=%.3f' % (i+1, discriminator_loss, generator_loss))\n",
        "\n",
        "\n",
        "#####Samples verification#####\n",
        "\n",
        "\t#We should regularly do some checkings on the training to see if it is going in the correct direction\n",
        "\t#We are saving a file with some generated images for inspection\n",
        "\tif (i+1) % 100 == 0 :\n",
        "\n",
        "\t\t_, accuracy_real = discriminator.evaluate(real_images, real_label, verbose=0) #We evaluate the discriminator on the real images\n",
        "\t\t_, accuracy_fake = discriminator.evaluate(fake_images, fake_label, verbose=0) #We evaluate the discriminator on the fake images\n",
        "\n",
        "\t\t#Those are the results of the accuracy of the discriminator. \n",
        "\t\t#The accuracy on real values should not be equal to 100%, else the learning process becomes saturated.\n",
        "\t\tprint('Accuracy of the discriminator real: %0.f%%, fake: %0.f%%' % (accuracy_real*100, accuracy_fake*100))\n",
        "\t\n",
        "\n",
        "\t\t#Saving some generated images to look at them\n",
        "\t\texamples = (fake_images + 1)/2\n",
        "\t\tn=3 # n*n will be the number of fake images shown\n",
        "\t\tfor k in range(n*n):\n",
        "\t\t\tplt.subplot(n, n, 1 + k)\n",
        "\t\t\tplt.axis('off')\n",
        "\t\t\tplt.imshow(examples[k])\n",
        "\t\tplt.savefig('Fake_images%03d' % (i+1))\n",
        "\t\tplt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1, d=0.530, g=0.987\n",
            "2, d=0.073, g=0.945\n",
            "3, d=0.554, g=0.985\n",
            "4, d=0.138, g=0.986\n",
            "5, d=0.249, g=0.976\n",
            "6, d=0.213, g=0.939\n",
            "7, d=0.069, g=0.798\n",
            "8, d=0.092, g=0.751\n",
            "9, d=0.109, g=0.644\n",
            "10, d=0.135, g=0.852\n",
            "11, d=0.110, g=1.252\n",
            "12, d=0.105, g=0.829\n",
            "13, d=0.085, g=0.934\n",
            "14, d=0.074, g=1.249\n",
            "15, d=0.054, g=0.439\n",
            "16, d=0.377, g=1.648\n",
            "17, d=0.297, g=0.752\n",
            "18, d=0.136, g=0.720\n",
            "19, d=0.223, g=0.751\n",
            "20, d=0.170, g=0.871\n",
            "21, d=0.112, g=0.791\n",
            "22, d=0.119, g=1.165\n",
            "23, d=0.109, g=0.945\n",
            "24, d=0.079, g=0.795\n",
            "25, d=0.103, g=1.467\n",
            "26, d=0.111, g=1.035\n",
            "27, d=0.066, g=0.848\n",
            "28, d=0.130, g=0.829\n",
            "29, d=0.107, g=0.875\n",
            "30, d=0.144, g=0.917\n",
            "31, d=0.079, g=1.007\n",
            "32, d=0.097, g=0.995\n",
            "33, d=0.095, g=0.864\n",
            "34, d=0.102, g=1.257\n",
            "35, d=0.070, g=1.153\n",
            "36, d=0.044, g=1.003\n",
            "37, d=0.039, g=0.919\n",
            "38, d=0.026, g=0.908\n",
            "39, d=0.055, g=1.180\n",
            "40, d=0.030, g=1.150\n",
            "41, d=0.045, g=0.919\n",
            "42, d=0.106, g=2.963\n",
            "43, d=0.135, g=1.047\n",
            "44, d=0.104, g=0.916\n",
            "45, d=0.124, g=0.740\n",
            "46, d=0.088, g=0.505\n",
            "47, d=0.191, g=0.707\n",
            "48, d=0.159, g=0.638\n",
            "49, d=0.171, g=0.637\n",
            "50, d=0.142, g=1.729\n",
            "51, d=0.235, g=0.094\n",
            "52, d=0.417, g=0.828\n",
            "53, d=0.235, g=0.789\n",
            "54, d=0.141, g=0.841\n",
            "55, d=0.101, g=0.818\n",
            "56, d=0.549, g=0.886\n",
            "57, d=0.378, g=0.870\n",
            "58, d=0.335, g=0.538\n",
            "59, d=0.292, g=2.261\n",
            "60, d=0.299, g=0.034\n",
            "61, d=0.727, g=0.730\n",
            "62, d=0.303, g=0.699\n",
            "63, d=0.288, g=0.695\n",
            "64, d=0.119, g=1.054\n",
            "65, d=0.191, g=0.814\n",
            "66, d=0.138, g=0.745\n",
            "67, d=0.117, g=1.173\n",
            "68, d=0.102, g=0.085\n",
            "69, d=0.363, g=1.773\n",
            "70, d=0.265, g=0.450\n",
            "71, d=0.264, g=0.820\n",
            "72, d=0.194, g=0.804\n",
            "73, d=0.167, g=0.904\n",
            "74, d=0.171, g=0.880\n",
            "75, d=0.081, g=0.846\n",
            "76, d=0.215, g=0.572\n",
            "77, d=0.180, g=1.171\n",
            "78, d=0.177, g=1.288\n",
            "79, d=0.103, g=1.000\n",
            "80, d=0.136, g=0.630\n",
            "81, d=0.089, g=0.786\n",
            "82, d=0.073, g=0.984\n",
            "83, d=0.070, g=0.947\n",
            "84, d=0.056, g=0.574\n",
            "85, d=0.068, g=1.486\n",
            "86, d=0.104, g=1.086\n",
            "87, d=0.102, g=0.818\n",
            "88, d=0.054, g=0.738\n",
            "89, d=0.045, g=0.840\n",
            "90, d=0.048, g=0.860\n",
            "91, d=0.049, g=0.869\n",
            "92, d=0.055, g=0.777\n",
            "93, d=0.042, g=0.987\n",
            "94, d=0.046, g=0.827\n",
            "95, d=0.036, g=1.125\n",
            "96, d=0.042, g=1.028\n",
            "97, d=0.039, g=0.723\n",
            "98, d=0.048, g=1.297\n",
            "99, d=0.049, g=1.121\n",
            "100, d=0.042, g=0.951\n",
            "Accuracy of the discriminator real: 100%, fake: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-9GvFqKVwZ_",
        "outputId": "f34d7fd2-070a-46fa-9cf9-b836367c74d5"
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Calculating the Inception Score\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "#We are shaping the last results in order to evaluate their inception score\n",
        "result=(examples*127.5+127.5).astype('float32')\n",
        "\n",
        "#InceptionV3() is an image recognition neural network which is used to calculate the inception score\n",
        "model = InceptionV3()\n",
        "\n",
        "#The InceptionV3() function accepts only entry in the shape of (299,299,3), so we need to resize all of our images to this shape\n",
        "data_list = list()\n",
        "for i in result:\n",
        "\tdata = resize(i, (299,299,3))\n",
        "\tdata_list.append(data)\n",
        " \n",
        "result=asarray(data_list)\n",
        "\n",
        "#We need to preprocess the data so that the predict() function from InceptionV3 can work\n",
        "#It gives us a probability distribution that needs to be transformed in order to get the inception score\n",
        "#This probability distribution depends on the number of classes perceived by the algorithm\n",
        "\n",
        "P_yx = model.predict(preprocess_input(result))\n",
        "\n",
        "#This is the probability that each image is in a class. The sum of this probability for an image is 1\n",
        "P_y = P_yx.mean(axis=0)\n",
        "\n",
        "#We are using the Kullback-Leibler divergence with logarithmic probabilities\n",
        "#This will give us the randomness of the probability we obtained; the less random the higher the inception score will be\n",
        "#We need the 'e' value in case the probability is 0, which would cause an infinity error\n",
        "e=1E-16\n",
        "KL = P_yx * (log(P_yx + e) - log(P_y + e))\n",
        "\n",
        "#We are making the sum of the values for each image\n",
        "sum_KL = KL.sum(axis=1)\n",
        "# Averaging on all the images and adding an exponential to counteract the previous logarithm\n",
        "#If the average of the sum is close to zero, it means no structure has been detected and the IS will be close to one\n",
        "IS = exp(mean(sum_KL))\n",
        "\n",
        "print('Inception score : ', IS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception score :  1.0617894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6olMRCYUfZUs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "393e1885-b009-435c-86a6-02d565c8923b"
      },
      "source": [
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(160,160,3)):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (5,5), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        " \n",
        "\tmodel.add(Conv2D(256, (5,5), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\t\n",
        "\tmodel.add(Conv2D(256, (5,5), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\n",
        "\tmodel.add(Conv2D(256, (5,5), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\n",
        "\tmodel.add(Conv2D(256, (5,5), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='linear'))    #change to 'sigmoid' for binary-crossentropy\n",
        "\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='mse', optimizer=opt, metrics=['accuracy'])   #change to 'binary-crossentropy'\n",
        "\treturn model\n",
        " \n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\t# foundation for 5x5 image\n",
        "\tn_nodes = 256 * 5 * 5\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((5, 5, 256)))\n",
        " \n",
        "\t# upsample to 10x10\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\t\t# upsample to 20x20\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\t\t# upsample to 40x40\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\t\t# upsample to 80x80\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\t\t# upsample to 160x160\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\n",
        "\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
        "\treturn model\n",
        " \n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "\td_model.trainable = False\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(g_model)\n",
        "\tmodel.add(d_model)\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='mse', optimizer=opt)    #change to 'binary-crossentropy'\n",
        "\treturn model\n",
        " \n",
        "# load and prepare cifar10 training images\n",
        "def load_real_samples():\n",
        "\tX = trainX.astype('float32')\n",
        "\treturn X\n",
        " \n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        " \n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = g_model.predict(x_input)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, n=2):\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\texamples = (examples + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tplt.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tplt.imshow(examples[i])\n",
        "\t# save plot to file\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tplt.savefig(filename)\n",
        "\tplt.close()\n",
        " \n",
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=2000):\n",
        "\t# prepare real samples\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\t# save plot\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\t# save the generator model tile file\n",
        "\tfilename = 'generator_model_%03d.h5' % (epoch+1)\n",
        "\tg_model.save(filename)\n",
        "\treturn x_fake\n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=800, n_batch=32):\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\tfake_image=trainX[0]\n",
        "\tfake_images=[]\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# enumerate batches over the training set\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# create training set for the discriminator\n",
        "\t\t\tX, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss, _ = d_model.train_on_batch(X, y)\n",
        "\t\t\t# prepare points in latent space as input for the generator\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\t# create inverted labels for the fake samples\n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\t# update the generator via the discriminator's error\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t\t# summarize loss on this batch\n",
        "\t\t\tprint('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "\t\t# evaluate the model performance, sometimes\n",
        "\t\tif (i+1) % 20 == 0:\n",
        "\t\t\tfake_image = (summarize_performance(i, g_model, d_model, dataset, latent_dim))\n",
        "\t\tif (i+1) % 1 == 0 and i>=797:\n",
        "\t\t\tfake_image = (summarize_performance(i, g_model, d_model, dataset, latent_dim))\n",
        "\t\t\tfake_images.append(fake_image)\n",
        "\treturn fake_images    #This is used to retrieve the Inception Score\n",
        " \n",
        "# size of the latent space\n",
        "latent_dim = 50\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = trainX.astype('float32')\n",
        "print(dataset.shape)\n",
        "# train model\n",
        "fake_images=train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(630, 160, 160, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2a75008a2ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m \u001b[0mfake_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-2a75008a2ac0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m    157\u001b[0m                         \u001b[0mX_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                         \u001b[0;31m# generate 'fake' examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                         \u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                         \u001b[0;31m# create training set for the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2a75008a2ac0>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[0;34m(g_model, latent_dim, n_samples)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# predict outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;31m# create 'fake' class labels (0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixEJteDt1E-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "dedaef88-bf9f-47e9-80b0-a547b36cb3d5"
      },
      "source": [
        "import numpy\n",
        "from math import floor\n",
        "from numpy import ones\n",
        "from numpy import expand_dims\n",
        "from numpy import log\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import exp\n",
        "from numpy.random import shuffle\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets import cifar10\n",
        "from skimage.transform import resize\n",
        "from numpy import asarray\n",
        " \n",
        "# scale an array of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        " \n",
        "# assumes images have any shape and pixels in [0,255]\n",
        "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
        "\t# load inception v3 model\n",
        "\tmodel = InceptionV3()\n",
        "\t# enumerate splits of images/predictions\n",
        "\tscores = list()\n",
        "\tn_part = floor(images.shape[0] / n_split)\n",
        "\tfor i in range(n_split):\n",
        "\t\t# retrieve images\n",
        "\t\tix_start, ix_end = i * n_part, (i+1) * n_part\n",
        "\t\tsubset = images[ix_start:ix_end]\n",
        "\t\t# convert from uint8 to float32\n",
        "\t\tsubset = subset.astype('float32')\n",
        "\t\t# scale images to the required size\n",
        "\t\tsubset = scale_images(subset, (299,299,3))\n",
        "\t\t# pre-process images, scale to [-1,1]\n",
        "\t\tsubset = preprocess_input(subset)\n",
        "\t\t# predict p(y|x)\n",
        "\t\tp_yx = model.predict(subset)\n",
        "\t\t# calculate p(y)\n",
        "\t\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
        "\t\t# calculate KL divergence using log probabilities\n",
        "\t\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
        "\t\t# sum over classes\n",
        "\t\tsum_kl_d = kl_d.sum(axis=1)\n",
        "\t\t# average over images\n",
        "\t\tavg_kl_d = mean(sum_kl_d)\n",
        "\t\t# undo the log\n",
        "\t\tis_score = exp(avg_kl_d)\n",
        "\t\t# store\n",
        "\t\tscores.append(is_score)\n",
        "\t# average across images\n",
        "\tis_avg, is_std = mean(scores), std(scores)\n",
        "\treturn is_avg, is_std\n",
        "for i in range(0, 9):\n",
        "\tplt.subplot(3,3, 1+i)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(fake_images[i])\n",
        "fake_images=result\n",
        "print(fake_images*128+128) #Convert to [0,255] for image representation\n",
        "\n",
        "# calculate inception score\n",
        "is_avg, is_std = calculate_inception_score(fake_images*128+128)\n",
        "print('score', is_avg, is_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b6cfcb373b09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ]
}